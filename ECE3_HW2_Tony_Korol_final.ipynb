{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECE3_HW2_Tony_Korol_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJcXzC1IYiDX"
      },
      "source": [
        "# ECE 3 : Homework 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUU2mXLwYe29"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "To get started, you should go through the following steps.\n",
        "- Rename this jupyter notebook by adding your name: e.g. `ECE3_HW2_<your-name>.ipynb`.\n",
        "- Complete all the exercises by directly editing your notebook.\n",
        "- Make sure that the coding portions run without errors.\n",
        "- You can also upload this file to Google Colab and edit it there instead of using Jupyter Notebook locally. Doing this helped resolve some issues with importing libraries in HW1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6_BURW6j3xn"
      },
      "source": [
        "## Problem 1 - Regression using the k-NN algorithm\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hhj4lhRum32i"
      },
      "source": [
        "For this exercise we will use the \"Diabetes\" dataset from the scikit-learn package.\n",
        "\n",
        "The following chunk of code loads the dataset and prints a full description of it. Run it and carefully go through the description.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hge0HWz8j3QT",
        "outputId": "6198577f-a641-48a7-ef49-dd78647b4d5e"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "dataset = load_diabetes()\n",
        "print(dataset.DESCR)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _diabetes_dataset:\n",
            "\n",
            "Diabetes dataset\n",
            "----------------\n",
            "\n",
            "Ten baseline variables, age, sex, body mass index, average blood\n",
            "pressure, and six blood serum measurements were obtained for each of n =\n",
            "442 diabetes patients, as well as the response of interest, a\n",
            "quantitative measure of disease progression one year after baseline.\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "  :Number of Instances: 442\n",
            "\n",
            "  :Number of Attributes: First 10 columns are numeric predictive values\n",
            "\n",
            "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
            "\n",
            "  :Attribute Information:\n",
            "      - Age\n",
            "      - Sex\n",
            "      - Body mass index\n",
            "      - Average blood pressure\n",
            "      - S1\n",
            "      - S2\n",
            "      - S3\n",
            "      - S4\n",
            "      - S5\n",
            "      - S6\n",
            "\n",
            "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
            "\n",
            "Source URL:\n",
            "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
            "\n",
            "For more information see:\n",
            "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
            "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTi1gUKbpGpb"
      },
      "source": [
        "We see that the dataset consists of 10 attributes, including demographic information (such as age and sex) and various health measurements (such as BMI and blood pressure) for 442 diabetes patients. It also includes a response variable for each one of the patients, which is a measure of the progression of their disease. \n",
        "\n",
        "The attributes (a.k.a. the features or the data or the samples or the inputs) and the response variable (a.k.a. the target or the output) are given to us in the form of NumPy arrays. Let's assign them to variables X and y respectively and inspect their shape. Try to think of what their shape should be before running the following block of code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P289dc4slst8",
        "outputId": "54f0ea5a-ab8f-4b65-913f-6549526f3786"
      },
      "source": [
        "X, y = dataset.data, dataset.target\n",
        "\n",
        "print(\"The attributes are inlcuded in a matrix of shape:\", X.shape)\n",
        "print(\"The response variables are included in a vector of length:\", y.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The attributes are inlcuded in a matrix of shape: (442, 10)\n",
            "The response variables are included in a vector of length: (442,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lPHu5EVs7SO"
      },
      "source": [
        "We see that both the data matrix and the target vector have 442 rows, that is because we have 442 patients, with one row of data corresponding to each one of them. The data matrix has 10 columns, because for each patient we collect 10 demographic and health measurements. The target array is just a vector (i.e. it has only 1 column) as for each patient we only have one response measurement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI3qrnHx_F4B"
      },
      "source": [
        "Now lets take a closer look at the target vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vac0BjYJs6qQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1cf7c19-a7e5-42dc-fb7d-d4862f310a08"
      },
      "source": [
        "print(\"The data type of the target is:\", y.dtype)\n",
        "print(\"Target values range from\", np.min(y), \"to\", np.max(y))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The data type of the target is: float64\n",
            "Target values range from 25.0 to 346.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJvA5O0VwUQ2"
      },
      "source": [
        "We see that the target here is a floating point number which can take a broad range of values. The exact value of the target is different for every patient. It is obvious that there is a connection between the health measurements and the demographic group of a person and the progression of that persons disease. More formally we can think that there is some function $f$ that maps the attributes to the target:\n",
        "\n",
        "$$\\text{disease progression} = f(age, sex, ..., s_6)$$\n",
        "\n",
        "However, we don't know what this function $f$ looks like! It could be that:\n",
        "\n",
        "$$f(age, sex, ..., s6) = \\text{age}^2 - 2*\\text{bmi}^3 + ... + \\frac{1}{s_6}$$\n",
        "\n",
        "or that:\n",
        "\n",
        "$$f(age, sex, ..., s6) = \\text{age} + 2*log(\\text{bmi}) + ... - {s_5}$$\n",
        "\n",
        "or really anything else! \n",
        "\n",
        "If we knew what the function was then we could help doctors give better advise to their patients (e.g. to lower their bmi or eat some food that's going to increase their $s_3$ measurement). \n",
        "\n",
        "Our goal in this exercise is to use the data that are available to us and try to deduce what is the relationship between the attributes and the target. Equivalently, you can also say that our goal is to estimate what the response variable would be for any set of values the attributes can take. This task is called **regression**!\n",
        "\n",
        "If our target was not a continuous variable but a discrete one, then our goal would be to use the data to decide to which one of a number of classes a sample belongs. This task is called **classification** and it is discussed more in depth on Lab 4, where we see that we can use similar algorithms for it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqlS96muFZJa"
      },
      "source": [
        "### Training and Test Sets\n",
        "\n",
        "To perform regression we will follow the following strategy. We will split our data in two groups, the training set and the test set. We will use the training set to deduce an approximation $f^\\prime$ of the real function $f$ and we will use the test set to check how close is our estimate of the response value when we use $f'$ to the observed response value. Typically, we assign most of our data to the training set and keep only about $20-30\\%$ of them for the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaU28k95KAvh"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAeATx-BINjC"
      },
      "source": [
        "### The k-NN algorithm for regression\n",
        "\n",
        "A simple regression algorithm is the k Nearest Neighbors algorithm. In k-NN regression the response of a datapoint is estimated as the average of the values of its k nearest neighbors.\n",
        "\n",
        "*   \"Nearest\" is defined with respect to some distance metric, usually that is the euclidean distance, however other distances are more appropriate for some applications\n",
        "*   k is a parameter chosen by the engineer, it is taken to be odd to avoid a situation where we can't decide because of a tie\n",
        "\n",
        "In this exercise you will implement the k-NN rule, using the euclidean distance, to estimate a response for each datapoint in the test set. Then you will compare that to the observed response to evaluate the performance of the algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Odxv61LqJM1o"
      },
      "source": [
        "#### (a) Write a function that calculates the euclidean distance between two points:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahnQeS2AJNc-"
      },
      "source": [
        "# Replace \"...\" with your code\n",
        "\n",
        "def eucl_dist(a, b):\n",
        "\n",
        "    return np.sum((np.subtract(a,b)) ** 2) ** (1/2)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFVqrWW5JP-4"
      },
      "source": [
        "#### (b) Write a function that receives as arguments a point and the training set, and calculates the distance of that point from all the points of the training set. The function should return a vector of length equal to the number of points in the training set. You can opt to you use the previous function that you wrote or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL0X779NJSwN"
      },
      "source": [
        "# Replace \"...\" with your code\n",
        "\n",
        "def dist_from_training_set(a, X):\n",
        "  array = np.empty(len(X),)\n",
        "  index_count = 0\n",
        "  for i in X:\n",
        "    distance = eucl_dist(i,a)\n",
        "    array[index_count]=distance\n",
        "    index_count = index_count + 1\n",
        "  return array\n",
        "\n",
        "#  return np.sum((X-a)**2,axis=1)**(1/2)\n",
        "\n",
        "# Alternatively you can write you own version this function, using a loop to\n",
        "# iteratively call the function from part (a) for each point in the training set"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyhFJV7YMDA2"
      },
      "source": [
        "#### (c) Write a function that receives as arguments a point, the training data, the training labels and an odd positive number k and implements that k-NN regression to return an estimated value. (Hint: modify your solution to Problem 1 - Part (c))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q3tefsTK5il"
      },
      "source": [
        "# Replace \"...\" with your code\n",
        "\n",
        "def kNN(a, X, y, k):\n",
        "\n",
        "    # calculate the distances of a from all the points in X\n",
        "    distances = dist_from_training_set(a, X) \n",
        "    # find the indices of X that correspond the k closest neighbors of a\n",
        "    nn_indices = distances.argsort()[:k][::-1]\n",
        "    # find the values of the k closest neighbors of a\n",
        "    nn_values = y[nn_indices]\n",
        "\n",
        "    # return the mean of the values that you found\n",
        "    return np.mean(nn_values)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H0FI5vANl6n"
      },
      "source": [
        "#### (d) Run 3NN regression for the first 5 points of the test set and report the estimate response values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IkGv5uJNhvI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe7e70ec-9464-47a9-bcbf-0189d99ec549"
      },
      "source": [
        "\n",
        "# Replace \"...\" with your code\n",
        "\n",
        "y_pred_3NN = np.empty(5,).T\n",
        "\n",
        "for idx in range(5):\n",
        "    y_pred_3NN[idx] = kNN(X_test[idx],X_train,y_train,3)\n",
        "\n",
        "print(\"array of values\")\n",
        "print(y_pred_3NN)\n",
        "print(\"first 5 full values\")\n",
        "for i in range(5):\n",
        "  print(y_pred_3NN[i])\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array of values\n",
            "[247.33333333 181.66666667 158.33333333 116.66666667 185.66666667]\n",
            "first 5 full values\n",
            "247.33333333333334\n",
            "181.66666666666666\n",
            "158.33333333333334\n",
            "116.66666666666667\n",
            "185.66666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q15hPhWla87G"
      },
      "source": [
        "#### (e) Use sklearn's KNeighborsRegressor class to verify your result from (b)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQW0KhLZbGhw",
        "outputId": "7d61d3be-36e5-4b90-e99b-ddaa979b11c7"
      },
      "source": [
        "# Replace \"...\" with your code\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "regressor = KNeighborsRegressor(n_neighbors=3)\n",
        "regressor.fit(X_train, y_train)\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "ypredtest = np.empty(5,)\n",
        "for i in range(5):\n",
        "  ypredtest[i]=y_pred[i]\n",
        "\n",
        "\n",
        "print(ypredtest)\n",
        "print(y_pred_3NN)\n",
        "print(ypredtest == y_pred_3NN)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[247.33333333 181.66666667 158.33333333 116.66666667 185.66666667]\n",
            "[247.33333333 181.66666667 158.33333333 116.66666667 185.66666667]\n",
            "[ True  True  True  True  True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvZ_ZNZnhrYi"
      },
      "source": [
        "### MSE - A regression performance metric\n",
        "\n",
        "A metric for the performance of a regression algorithm is the Mean Squared Error (MSE) which is defined as:\n",
        "\n",
        "$$MSE = \\sum_n (y_{pred} - y_{true})^2$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUwRUoWHN6YL"
      },
      "source": [
        "#### (f) Write a function that calculates the MSE. The run 3NN regression on the test set (all of it, not just the first 5 points) and print the MSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_z4eC3hOG6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4560c6bd-3f08-422f-bb01-decc614f6f37"
      },
      "source": [
        "# Replace \"...\" with your code\n",
        "\n",
        "def MSE(a, b):\n",
        "\n",
        "    return np.sum(np.subtract(a,b)**2)/len(b)\n",
        "\n",
        "y_pred_3NN = regressor.predict(X_test)\n",
        "\n",
        "print(y_pred_3NN.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "MSE_3NN = MSE(y_pred_3NN,y_test)\n",
        "print(MSE_3NN)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(89,)\n",
            "(89,)\n",
            "4415.551810237203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id-r8WULO2MS"
      },
      "source": [
        "#### (g) Plot the MSE for the kNN algorithm on the test for different values of k up to 11. What do you observe? How do you explain this?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhUte_q9l4UK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "5912170e-d3a6-460e-ecbd-8ec3ea50a30a"
      },
      "source": [
        "# Replace \"...\" with your code\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "mse = []\n",
        "for k in range(1, 12):\n",
        "    regressor = KNeighborsRegressor(n_neighbors=k)\n",
        "    regressor.fit(X_train,y_train)\n",
        "    y_pred = regressor.predict(X_test)\n",
        "    mse.append(MSE(y_pred,y_test))\n",
        "\n",
        "plt.plot(np.arange(1,12), mse)\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('MSE')\n",
        "plt.grid()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yldqXwuwljxi"
      },
      "source": [
        "(1g) I observe that the MSE is inversely proportional to K, because as the number of neighbors (k) increases, the MSE decreases significantly. This happens because with more neighbors, the algorithm has more reference points with which to make an accurate prediction. The reason the MSE changes is because there are more points being used to predict the response variable as k changes, so the predictions become more informed. If k was to become too large, the MSE may increase again depending on the data presented."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEzl8zxLlDmo"
      },
      "source": [
        "## Problem 2 - Linear Independence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1z01i1un9Cm"
      },
      "source": [
        "\n",
        "\n",
        "#### (a)   Verify that $c_1 = [0, 0, 1]$, $c_2 = [0, 1, 0]$, $c_3 = [1, 1, 0]$ are linearly independent vectors. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKQDQdQHUr2x"
      },
      "source": [
        "#### (b)   Recall the definition of basis vectors. Verify that any 3-dimensional vector $b$ can be written as a linear combination of the basis vectors:\n",
        "\n",
        "$\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:a_1=\\begin{bmatrix}\n",
        "-1\\\\\n",
        "0\\\\\n",
        "3\n",
        "\\end{bmatrix}$, $a_2=\\begin{bmatrix}\n",
        "1\\\\\n",
        "2\\\\\n",
        "-3\n",
        "\\end{bmatrix}$, $a_3=\\begin{bmatrix}\n",
        "4\\\\\n",
        "-2\\\\\n",
        "3\n",
        "\\end{bmatrix}$\n",
        "\n",
        "**Note**: An explanation (~100 words) for each part should be enough."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIvqrTft-eN_"
      },
      "source": [
        "#### Answer:\n",
        "\n",
        "(a) In order to prove linear independence, the vectors should only add up to 0 when their coefficients are 0 as well. By putting them in a matrix and solving for the homogeneous solution, we can see that the vectors are linearly independent as the coefficients: x, y, and z must be 0 to satisfy the matrix\n",
        ":\n",
        "\n",
        "$\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\begin{bmatrix}\n",
        "0 & 0 & 1 & 0\\\\\n",
        "0 & 1 & 1 & 0\\\\\n",
        "1 & 0 & 0 & 0\n",
        "\\end{bmatrix}\n",
        "=\\begin{bmatrix}\n",
        "1 & 0 & 0 & 0\\\\\n",
        "0 & 1 & 1 & 0\\\\\n",
        "0 & 0 & 1 & 0\n",
        "\\end{bmatrix}\n",
        "=\\begin{bmatrix}\n",
        "[1] & 0 & 0 & 0\\\\\n",
        "0 & [1] & 0 & 0\\\\\n",
        "0 & 0 & [1] & 0\n",
        "\\end{bmatrix}$\n",
        "\n",
        "There is a unique pivot in every row, which means the only linear combination that works is $0c_1+0c_2+0c_3=0$, so the vectors are linearly independent\n",
        "\n",
        "\n",
        "(b) Vector b can be represented as a linear combination of $a_1,a_2,$ and $a_3$ if the vectors are all linearly independent and span R3. The equation: $x*a_1+y*a_2+z*a_3$ must produce any vector in R3. This is represented by the matrix:\n",
        "$\\begin{bmatrix}\n",
        "-1 & 1 & 4 \\\\\n",
        "0 & 2 & -2 \\\\\n",
        "3 & -3 & 3 \n",
        "\\end{bmatrix}$ which $=\\begin{bmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "0 & 1 & 0 \\\\\n",
        "0 & 0 & 1 \n",
        "\\end{bmatrix}$ by row reduction\n",
        "\n",
        "and this parametric form holds with arbitrary coefficients x,y,z:\n",
        "\n",
        "$x\\begin{bmatrix}\n",
        "1\\\\\n",
        "0\\\\\n",
        "0\n",
        "\\end{bmatrix}+y\\begin{bmatrix}\n",
        "0\\\\\n",
        "1\\\\\n",
        "0\n",
        "\\end{bmatrix}+z\\begin{bmatrix}\n",
        "0\\\\\n",
        "0\\\\\n",
        "1\n",
        "\\end{bmatrix}=\\begin{bmatrix}\n",
        "b_1\\\\\n",
        "b_2\\\\\n",
        "b_3\n",
        "\\end{bmatrix}$\n",
        "\n",
        "$b_1,b_2,b_3$ are thus represented by a linear combination of the unit vectors for R3 and that means any vector \"b\" is included in the span of the reduced basis vectors, $a_1,a_2$, and $a_3$ and it can be any vector in R3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjvKqBDevusc"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}